{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":155833,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":132420,"modelId":155211}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets accelerate peft trl einops","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-04T17:23:52.713699Z","iopub.execute_input":"2024-11-04T17:23:52.714583Z","iopub.status.idle":"2024-11-04T17:24:04.368264Z","shell.execute_reply.started":"2024-11-04T17:23:52.714538Z","shell.execute_reply":"2024-11-04T17:24:04.367055Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.13.2)\nRequirement already satisfied: trl in /opt/conda/lib/python3.10/site-packages (0.12.0)\nRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (0.8.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from trl) (13.7.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:24:04.370705Z","iopub.execute_input":"2024-11-04T17:24:04.371533Z","iopub.status.idle":"2024-11-04T17:24:15.739392Z","shell.execute_reply.started":"2024-11-04T17:24:04.371483Z","shell.execute_reply":"2024-11-04T17:24:15.738171Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.44.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport torch\nimport time\nfrom datasets import load_dataset, Dataset\nfrom peft import LoraConfig, prepare_model_for_kbit_training, PeftModel, get_peft_model\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    AutoTokenizer,\n    TrainingArguments,\n    pipeline,\n    logging,\n    Trainer\n)\nfrom accelerate import Accelerator\nfrom trl import SFTTrainer","metadata":{"execution":{"iopub.status.busy":"2024-11-04T18:02:48.709976Z","iopub.execute_input":"2024-11-04T18:02:48.710426Z","iopub.status.idle":"2024-11-04T18:02:57.747374Z","shell.execute_reply.started":"2024-11-04T18:02:48.710384Z","shell.execute_reply":"2024-11-04T18:02:57.746549Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load SNLI dataset\ndataset = load_dataset(\"snli\")\n\n# Select indices for sampling\ntrain_indices = list(range(0, len(dataset[\"train\"]), 550))[:1000]\nvalidation_indices = list(range(0, len(dataset[\"validation\"]), 100))[:100]\ntest_indices = list(range(0, len(dataset[\"test\"]), 100))[:100]\n\n# Subset datasets using the selected indices\ntrain_data = dataset[\"train\"].select(train_indices)\nvalidation_data = dataset[\"validation\"].select(validation_indices)\ntest_data = dataset[\"test\"].select(test_indices)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T18:05:18.729304Z","iopub.execute_input":"2024-11-04T18:05:18.729717Z","iopub.status.idle":"2024-11-04T18:05:23.245833Z","shell.execute_reply.started":"2024-11-04T18:05:18.729678Z","shell.execute_reply":"2024-11-04T18:05:23.244900Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Model\nbase_model = \"microsoft/phi-2\"\n\n# Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=True)\ntokenizer.pad_token=tokenizer.eos_token\ntokenizer.padding_side=\"right\"","metadata":{"execution":{"iopub.status.busy":"2024-11-04T18:03:54.748533Z","iopub.execute_input":"2024-11-04T18:03:54.749462Z","iopub.status.idle":"2024-11-04T18:03:54.997090Z","shell.execute_reply.started":"2024-11-04T18:03:54.749405Z","shell.execute_reply":"2024-11-04T18:03:54.996317Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Quantization configuration\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=False,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T18:04:58.077468Z","iopub.execute_input":"2024-11-04T18:04:58.077899Z","iopub.status.idle":"2024-11-04T18:04:58.084521Z","shell.execute_reply.started":"2024-11-04T18:04:58.077844Z","shell.execute_reply":"2024-11-04T18:04:58.083444Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\n# # Load base moodel\n# model = AutoModelForCausalLM.from_pretrained(\n#     base_model,\n#     quantization_config=bnb_config,\n#     trust_remote_code=True,\n#     low_cpu_mem_usage=True,\n#     device_map={\"\": 0},\n#     revision=\"refs/pr/23\" #the main version of Phi-2 doesn’t support gradient checkpointing (while training this model)\n# )\n\n# model.config.use_cache = False\n# model.config.pretraining_tp = 1\n# model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cls_model = AutoModelForSequenceClassification.from_pretrained(base_model,\n    quantization_config=bnb_config,\n    trust_remote_code=True,\n    low_cpu_mem_usage=True,\n    device_map={\"\": 0},\n    num_labels=3)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:24:20.305441Z","iopub.execute_input":"2024-11-04T17:24:20.305790Z","iopub.status.idle":"2024-11-04T17:24:24.193324Z","shell.execute_reply.started":"2024-11-04T17:24:20.305759Z","shell.execute_reply":"2024-11-04T17:24:24.192562Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cb18f733c66459295c8cd3795a0d612"}},"metadata":{}},{"name":"stderr","text":"Some weights of PhiForSequenceClassification were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# cls_model.config.use_cache = False\ncls_model.config.pretraining_tp = 1\ncls_model = prepare_model_for_kbit_training(cls_model, use_gradient_checkpointing=True)\n\n# Define LoRA config\nlora_config = LoraConfig(\n    r=8,  # rank\n    lora_alpha=16,  # alpha\n    lora_dropout=0.1,  # dropout\n    task_type=\"SEQ_CLS\"  # task type\n)\n\ncls_model = get_peft_model(cls_model, lora_config)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:24:26.540374Z","iopub.execute_input":"2024-11-04T17:24:26.541257Z","iopub.status.idle":"2024-11-04T17:24:26.858195Z","shell.execute_reply.started":"2024-11-04T17:24:26.541214Z","shell.execute_reply":"2024-11-04T17:24:26.857318Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"if tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n    tokenizer.pad_token_id = tokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:24:28.806005Z","iopub.execute_input":"2024-11-04T17:24:28.806733Z","iopub.status.idle":"2024-11-04T17:24:28.811067Z","shell.execute_reply.started":"2024-11-04T17:24:28.806692Z","shell.execute_reply":"2024-11-04T17:24:28.810095Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(\"Unique labels in training data:\", set(test_data['label']))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:24:33.515502Z","iopub.execute_input":"2024-11-04T17:24:33.516242Z","iopub.status.idle":"2024-11-04T17:24:33.522379Z","shell.execute_reply.started":"2024-11-04T17:24:33.516202Z","shell.execute_reply":"2024-11-04T17:24:33.521428Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Unique labels in training data: {0, 1, 2}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Remove entries with label -1 from the validation dataset\nvalid_labels = [0, 1, 2]\n\n# Filter the validation dataset\nfiltered_val_data = validation_data.filter(lambda x: x['label'] in valid_labels)\n\nprint(\"Unique labels in filtered validation data:\", set(filtered_val_data['label']))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T18:05:39.666863Z","iopub.execute_input":"2024-11-04T18:05:39.667780Z","iopub.status.idle":"2024-11-04T18:05:39.678675Z","shell.execute_reply.started":"2024-11-04T18:05:39.667736Z","shell.execute_reply":"2024-11-04T18:05:39.677769Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Unique labels in filtered validation data: {0, 1, 2}\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    labels = examples['label']\n    assert all(label in [0, 1, 2] for label in labels), \"Labels must be in the range of 0 to 2 for 3-class classification.\"\n    return tokenizer(\n        examples['premise'], \n        examples['hypothesis'], \n        truncation=True, \n        padding='max_length',  \n        max_length=256         \n    )\n\ntrain_encodings = preprocess_function(train_data)\nvalidation_encodings = preprocess_function(filtered_val_data)\ntest_encodings = preprocess_function(test_data)\n\nclass NliDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = NliDataset(train_encodings, train_data['label'])\nvalidation_dataset = NliDataset(validation_encodings, filtered_val_data['label'])\ntest_dataset = NliDataset(test_encodings, test_data['label'])\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T18:05:41.975597Z","iopub.execute_input":"2024-11-04T18:05:41.976517Z","iopub.status.idle":"2024-11-04T18:05:42.125783Z","shell.execute_reply.started":"2024-11-04T18:05:41.976468Z","shell.execute_reply":"2024-11-04T18:05:42.124761Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy='epoch',  \n    save_strategy='epoch',        \n    num_train_epochs=5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    logging_dir='./logs',\n    logging_steps=10,\n    save_total_limit=5,\n    load_best_model_at_end=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:25:11.153828Z","iopub.execute_input":"2024-11-04T17:25:11.154234Z","iopub.status.idle":"2024-11-04T17:25:11.191485Z","shell.execute_reply.started":"2024-11-04T17:25:11.154197Z","shell.execute_reply":"2024-11-04T17:25:11.190552Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"cls_model.config.pad_token_id = tokenizer.pad_token_id","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:25:18.906901Z","iopub.execute_input":"2024-11-04T17:25:18.908176Z","iopub.status.idle":"2024-11-04T17:25:18.914112Z","shell.execute_reply.started":"2024-11-04T17:25:18.908122Z","shell.execute_reply":"2024-11-04T17:25:18.912637Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# import os\n# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:25:21.441340Z","iopub.execute_input":"2024-11-04T17:25:21.441741Z","iopub.status.idle":"2024-11-04T17:25:21.446650Z","shell.execute_reply.started":"2024-11-04T17:25:21.441702Z","shell.execute_reply":"2024-11-04T17:25:21.445565Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=cls_model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=validation_dataset,\n    compute_metrics=lambda p: {'accuracy': accuracy_score(np.argmax(p.predictions, axis=1), p.label_ids)}\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:25:23.317745Z","iopub.execute_input":"2024-11-04T17:25:23.318753Z","iopub.status.idle":"2024-11-04T17:25:24.115670Z","shell.execute_reply.started":"2024-11-04T17:25:23.318545Z","shell.execute_reply":"2024-11-04T17:25:24.114691Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\ntrainer.train()\nend_time = time.time()\n\n# Save the model \ncls_model.save_pretrained('/kaggle/working/fine_tuned_model')\nprint(\"Time taken to fine-tune the model:\", end_time - start_time)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**EVALUATE**","metadata":{}},{"cell_type":"code","source":"eval_tokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=True)\neval_tokenizer.pad_token= eval_tokenizer.eos_token\neval_tokenizer.padding_side=\"right\"","metadata":{"execution":{"iopub.status.busy":"2024-11-04T18:00:29.276814Z","iopub.execute_input":"2024-11-04T18:00:29.277202Z","iopub.status.idle":"2024-11-04T18:00:29.584319Z","shell.execute_reply.started":"2024-11-04T18:00:29.277168Z","shell.execute_reply":"2024-11-04T18:00:29.583497Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"final_model = PeftModel.from_pretrained(cls_model,\"/kaggle/input/results/pytorch/default/1/fine_tuned_model\",is_trainable=False)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:32:45.485834Z","iopub.execute_input":"2024-11-04T17:32:45.486270Z","iopub.status.idle":"2024-11-04T17:32:45.852852Z","shell.execute_reply.started":"2024-11-04T17:32:45.486232Z","shell.execute_reply":"2024-11-04T17:32:45.852033Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Trainer for the pretrained model\npretrained_trainer = Trainer(\n    model=cls_model,\n    args=TrainingArguments(\n        output_dir='./pretrained_results',\n        per_device_eval_batch_size=16,\n        do_train=False,\n        do_eval=True,\n    ),\n    eval_dataset=test_dataset,\n    compute_metrics=lambda p: {'accuracy': accuracy_score(np.argmax(p.predictions, axis=1), p.label_ids)}\n)\n\npretrained_eval_results = pretrained_trainer.evaluate()\npretrained_accuracy = pretrained_eval_results[\"eval_accuracy\"]\nprint(\"Pretrained Model Accuracy on Test Set:\", pretrained_accuracy)\n\n# Evaluate the fine-tuned model on the test dataset\nfine_tuned_trainer = Trainer(\n    model=final_model,\n    args=TrainingArguments(\n        output_dir='./fine_tuned_results',\n        per_device_eval_batch_size=16,\n        do_train=False,\n        do_eval=True,\n    ),\n    eval_dataset=test_dataset,\n    compute_metrics=lambda p: {'accuracy': accuracy_score(np.argmax(p.predictions, axis=1), p.label_ids)}\n)\n\nfine_tuned_eval_results = fine_tuned_trainer.evaluate()\nfine_tuned_accuracy = fine_tuned_eval_results[\"eval_accuracy\"]\n\nprint(f\"Accuracy Comparison:\\n- Pretrained Model: {pretrained_accuracy:.2f}\\n- Fine-tuned Model: {fine_tuned_accuracy:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:44:39.981670Z","iopub.execute_input":"2024-11-04T17:44:39.982593Z","iopub.status.idle":"2024-11-04T17:46:08.456660Z","shell.execute_reply.started":"2024-11-04T17:44:39.982552Z","shell.execute_reply":"2024-11-04T17:46:08.455781Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4/4 00:30]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Pretrained Model Accuracy on Test Set: 0.32\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4/4 00:29]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Accuracy Comparison:\n- Pretrained Model: 0.32\n- Fine-tuned Model: 0.59\n","output_type":"stream"}]},{"cell_type":"code","source":"# Total parameters in the model\ntotal_params = sum(p.numel() for p in final_model.parameters())\n# Count trainable parameters\ntrainable_params = sum(p.numel() for p in final_model.parameters() if p.requires_grad)\n\nprint(f\"Total Parameters: {total_params}, Trainable Parameters: {trainable_params}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:48:13.347616Z","iopub.execute_input":"2024-11-04T17:48:13.348033Z","iopub.status.idle":"2024-11-04T17:48:13.369038Z","shell.execute_reply.started":"2024-11-04T17:48:13.347993Z","shell.execute_reply":"2024-11-04T17:48:13.368001Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Total Parameters: 1399459840, Trainable Parameters: 7680\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}